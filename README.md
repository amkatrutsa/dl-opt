# Optimization methods for training neural networks

1. Basic concepts: models, autograd, generalization, local minima and their features
2. Ingredients of basic optimizers
3. Key elements of models
4. Federated learning
5. Few-bit optimizers 
6. Privacy-aware optimizers
7. From first-order stochastic methods to higher order optimizers
8. Paralellism in training large neural networks
9. Meta optimizers
10. Challenges and perspectives  
